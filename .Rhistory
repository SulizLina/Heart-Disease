dataset[dataset$fbs != "0" & dataset$fbs != "1",]
dataset[dataset$restecg != "0" & dataset$restecg != "1" & dataset$restecg != "2" ,]
dataset[dataset$exang != "0" & dataset$exang != "1",]
dataset[dataset$slope != "0" & dataset$slope != "1" & dataset$slope != "2" ,]
dataset[dataset$thal != "1" & dataset$thal != "2" & dataset$thal != "3" ,]
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]}
a=getmode(dataset$ca)
print(a)
dataset[dataset$ca=="4","ca"]<-a
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]}
b=getmode(dataset$thal)
print(b)
dataset[dataset$thal=="0","thal"]<-b
dataset$trestbps <- ifelse(dataset$trestbps <=90, "Low",
ifelse(dataset$trestbps <= 120, "Normal",
ifelse(dataset$trestbps <= 129, "Elevated",
ifelse(dataset$trestbps <= 139, "High Stage 1",
ifelse(dataset$trestbps <= 180, "High Stage 2",
ifelse(dataset$trestbps > 180, "High Stage 3",0))))))
trestbpsdis <- dataset$trestbps
print(trestbpsdis)
AgeBeforeDis <- dataset$age
dataset$age <- ifelse(dataset$age <= 16, "Children",
ifelse(dataset$age <= 39, "Young Adults",
ifelse(dataset$age <= 59, "Middle-aged Adults",
ifelse(dataset$age < 99, "Old Adults",0))))
agedis <- dataset$age
print(agedis)
min_max_normalize <- function(x) {
(x - min(x)) / (max(x) - min(x))}
dataset$chol <- min_max_normalize(dataset$chol)
print(dataset$chol)
dataset$oldpeak <- min_max_normalize(dataset$oldpeak)
print(dataset$oldpeak)
dataset$thalach <- min_max_normalize(dataset$thalach)
print(dataset$thalach)
sexencoding <- dataset$sex
print(sexencoding)
dataset$trestbps=factor(dataset$trestbps,levels=c("Low","Normal","Elevated","High Stage 1","High Stage 2","High Stage 3"),labels=c(0,1,2,3,4,5))
dataset$age=factor(dataset$age,levels=c("Children","Young Adults","Middle-aged Adults","Old Adults"),labels=c(0,1,2,3))
csex=chisq.test(dataset$sex , dataset$target)
print(csex)
ccp=chisq.test(dataset$cp , dataset$target)
print(ccp)
cfbs=chisq.test(dataset$fbs , dataset$target)
print(cfbs)
crestecg=chisq.test(dataset$restecg , dataset$target)
print(crestecg)
cexang=chisq.test(dataset$exang , dataset$target)
print(cexang)
cslope=chisq.test(dataset$slope , dataset$target)
print(cslope)
cca=chisq.test(dataset$ca , dataset$target)
print(cca)
cthal=chisq.test(dataset$thal , dataset$target)
print(cthal)
cage= chisq.test(dataset$age, dataset$target)
print(cage)
ctrestbps=chisq.test(dataset$trestbps ,dataset$target)
print(ctrestbps)
cchol=cor(dataset$chol ,dataset$target)
print(cchol)
cthalach=cor(dataset$thalach ,dataset$target)
print(cthalach)
coldpeak=cor(dataset$oldpeak ,dataset$target)
print(coldpeak)
dataset <- dataset[, -which(names(dataset) == "fbs")]
head(dataset)
ncol(dataset)
nrow(dataset)
dataset$target <- as.factor(dataset$target)
install.packages("partykit")
library(party)
library(partykit)
library(RWeka)
install.packages("partykit")
install.packages("partykit")
dataBeforC<-dataset #in case we need the old dataset(with the class label)
dataset <- dataset[, -which(names(dataset) == "target")]
dataset$age <- AgeBeforeDis
dataset$sex <- as.numeric(dataset$sex )
dataset$cp <- as.numeric(dataset$cp )
dataset$trestbps <- as.numeric(dataset$trestbps  )
dataset$restecg <- as.numeric(dataset$restecg )
dataset$thalach <- as.numeric(dataset$thalach)
dataset$exang <- as.numeric(dataset$exang)
dataset$slope <- as.numeric(dataset$slope)
dataset$ca <- as.numeric(dataset$ca)
dataset$thal <- as.numeric(dataset$thal)
dataset$age <- as.numeric(dataset$age)
str(dataset)
install.packages("factoextra")
library(factoextra)
library(NbClust)
library(cluster)
km <- kmeans(dataset, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
km
fviz_cluster(list(data = dataset, cluster = km$cluster),
ellipse.type = "norm", geom = "point", stand = FALSE,
palette = "jco", ggtheme = theme_classic())
sil <- silhouette(km$cluster, dist(dataset))
rownames(sil) <- rownames(dataset)
fviz_silhouette(sil)
km$totss
cluster_assignments <- c(km$cluster)
ground_truth_labels <- c(dataBeforC$target)
data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)
# Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
n <- nrow(data)
precision_sum <- 0
recall_sum <- 0
for (i in 1:n) {
cluster <- data$cluster[i]
label <- data$label[i]
# Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
}
# Calculate average precision and recall
precision <- precision_sum / n
recall <- recall_sum / n
return(list(precision = precision, recall = recall))
}
# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)
# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall
# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
km <- kmeans(dataset, 3, iter.max = 140 , algorithm="Lloyd", nstart=100)
km
fviz_cluster(list(data = dataset, cluster = km$cluster),
ellipse.type = "norm", geom = "point", stand = FALSE,
palette = "jco", ggtheme = theme_classic())
sil <- silhouette(km$cluster, dist(dataset))
rownames(sil) <- rownames(dataset)
fviz_silhouette(sil)
cluster_assignments <- c(km$cluster)
ground_truth_labels <- c(dataBeforC$target)
data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)
# Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
n <- nrow(data)
precision_sum <- 0
recall_sum <- 0
for (i in 1:n) {
cluster <- data$cluster[i]
label <- data$label[i]
# Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
}
# Calculate average precision and recall
precision <- precision_sum / n
recall <- recall_sum / n
return(list(precision = precision, recall = recall))
}
# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)
# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall
# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
km <- kmeans(dataset, 4, iter.max = 140 , algorithm="Lloyd", nstart=100)
km
fviz_cluster(list(data = dataset, cluster = km$cluster),
ellipse.type = "norm", geom = "point", stand = FALSE,
palette = "jco", ggtheme = theme_classic())
sil <- silhouette(km$cluster, dist(dataset))
rownames(sil) <- rownames(dataset)
fviz_silhouette(sil)
cluster_assignments <- c(km$cluster)
ground_truth_labels <- c(dataBeforC$target)
data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)
# Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
n <- nrow(data)
precision_sum <- 0
recall_sum <- 0
for (i in 1:n) {
cluster <- data$cluster[i]
label <- data$label[i]
# Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
}
# Calculate average precision and recall
precision <- precision_sum / n
recall <- recall_sum / n
return(list(precision = precision, recall = recall))
}
# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)
# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall
# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
fviz_nbclust(dataset, kmeans, method = "silhouette")+labs(subtitle ="Silhouette method")
km <- kmeans(dataset, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
km
fviz_cluster(list(data = dataset, cluster = km$cluster),
ellipse.type = "norm", geom = "point", stand = FALSE,
palette = "jco", ggtheme = theme_classic())
sil <- silhouette(km$cluster, dist(dataset))
rownames(sil) <- rownames(dataset)
fviz_silhouette(sil)
#total within-cluster-sum of square
twss <- sum(km$withinss)
print(twss)
source("~/Downloads/cluster lab script(1).R")
plot(k, type='b', avg_sil, xlab='Number of clusters', ylab='Average Silhouette Scores', frame=FALSE)
library(factoextra)
fviz_nbclust(dataset, km, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
install.packages("ggplot2")
library(mlbench)
library(aod)
library(mlbench)
library(dplyr)
library(ggplot2)
library(pROC)
library(stats)
library(rpart.plot)
library(randomForest)
library(gbm)
library(class)
library(patchwork)
library(e1071)
library(caret)
data= read.csv('DataSet/heart.csv')
head(data)
sum(duplicated(data))
data[c(61,65,119,669),]
dataset <- data[!duplicated(data), ]
dataset
sum(duplicated(dataset))
ncol(dataset)
nrow(dataset)
summary(dataset$age)
var(dataset$age)
summary(dataset$trestbps)
var(dataset$trestbps)
summary (dataset$chol)
var(dataset$chol)
summary(dataset$thalach)
var(dataset$thalach)
summary(dataset$oldpeak)
var(dataset$oldpeak)
boxplot(dataset$age)
boxplot(dataset$trestbps)
boxplot(dataset$chol)
boxplot(dataset$thalach)
boxplot(dataset$oldpeak)
tab <- dataset$target %>% table()
percentages <- tab %>% prop.table() %>% round(3) * 100
txt <- paste0(names(tab), '\n', percentages, '%')
pie(tab, labels = txt, main="percentage of the target")
ggplot(dataset, aes(x = sex, fill = as.factor(target))) +
geom_bar(stat = "count", position = "stack", width = 0.6, show.legend = TRUE) +
geom_text(aes(label = after_stat(count)), stat = 'count', position = position_stack(vjust = 0.5)) +
labs(x = "Sex", y = "Count",fill="target")
ggplot(dataset, aes(x = cp, fill = as.factor(target))) +
geom_bar(stat = "count", position = "stack", width = 0.6, show.legend = TRUE) +
geom_text(aes(label = after_stat(count)), stat = 'count', position = position_stack(vjust = 0.5)) +
labs(x = "cp", y = "Count",fill="target")
ggplot(dataset, aes(x = ca, fill = as.factor(target))) +
geom_bar(stat = "count", position = "stack", width = 0.6, show.legend = TRUE) +
geom_text(aes(label = after_stat(count)), stat = 'count', position = position_stack(vjust = 0.5)) +
labs(x = "ca", y = "Count",fill="target")
plot(dataset$target,dataset$thalach)
plot(dataset$age, dataset$trestbps, pch = 16, col = "black", xlab = "Age", ylab = "trestbps", main = "Scatter Plot for Age and trestbps")
abline(lm(dataset$trestbps ~ dataset$age), col = "red", lwd = 2)
plot(dataset$thalach, dataset$oldpeak, pch = 16, col = "black", xlab = "thalach", ylab = "oldpeak", main = "Scatter Plot for thalach and oldpeak")
abline(lm(dataset$oldpeak ~ dataset$thalach), col = "red", lwd = 2)
plot(dataset$chol,dataset$target)
ggplot(dataset, aes(x = fbs, fill = as.factor(target))) +
geom_bar(stat = "count", position = "stack", width = 0.6, show.legend = TRUE) +
geom_text(aes(label = after_stat(count)), stat = 'count', position = position_stack(vjust = 0.5)) +
labs(x = "fbs", y = "Count",fill="target")
sum(is.na(data))
boxplot.stats(dataset$age)$out
boxplot.stats(dataset$trestbps)$out
boxplot.stats(dataset$chol)$out
boxplot.stats(dataset$thalach)$out
boxplot.stats(dataset$oldpeak)$out
dataset[129,5]=246.5
dataset[dataset$ca != "3" & dataset$ca != "1" & dataset$ca != "2" & dataset$ca != "0",]
dataset[dataset$sex != "0" & dataset$sex!= "1",]
dataset[dataset$fbs != "0" & dataset$fbs != "1",]
dataset[dataset$restecg != "0" & dataset$restecg != "1" & dataset$restecg != "2" ,]
dataset[dataset$exang != "0" & dataset$exang != "1",]
dataset[dataset$slope != "0" & dataset$slope != "1" & dataset$slope != "2" ,]
dataset[dataset$thal != "1" & dataset$thal != "2" & dataset$thal != "3" ,]
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]}
a=getmode(dataset$ca)
print(a)
dataset[dataset$ca=="4","ca"]<-a
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]}
b=getmode(dataset$thal)
print(b)
dataset[dataset$thal=="0","thal"]<-b
dataset$trestbps <- ifelse(dataset$trestbps <=90, "Low",
ifelse(dataset$trestbps <= 120, "Normal",
ifelse(dataset$trestbps <= 129, "Elevated",
ifelse(dataset$trestbps <= 139, "High Stage 1",
ifelse(dataset$trestbps <= 180, "High Stage 2",
ifelse(dataset$trestbps > 180, "High Stage 3",0))))))
trestbpsdis <- dataset$trestbps
print(trestbpsdis)
AgeBeforeDis <- dataset$age
dataset$age <- ifelse(dataset$age <= 16, "Children",
ifelse(dataset$age <= 39, "Young Adults",
ifelse(dataset$age <= 59, "Middle-aged Adults",
ifelse(dataset$age < 99, "Old Adults",0))))
agedis <- dataset$age
print(agedis)
min_max_normalize <- function(x) {
(x - min(x)) / (max(x) - min(x))}
dataset$chol <- min_max_normalize(dataset$chol)
print(dataset$chol)
dataset$oldpeak <- min_max_normalize(dataset$oldpeak)
print(dataset$oldpeak)
dataset$thalach <- min_max_normalize(dataset$thalach)
print(dataset$thalach)
sexencoding <- dataset$sex
print(sexencoding)
dataset$trestbps=factor(dataset$trestbps,levels=c("Low","Normal","Elevated","High Stage 1","High Stage 2","High Stage 3"),labels=c(0,1,2,3,4,5))
dataset$age=factor(dataset$age,levels=c("Children","Young Adults","Middle-aged Adults","Old Adults"),labels=c(0,1,2,3))
csex=chisq.test(dataset$sex , dataset$target)
print(csex)
ccp=chisq.test(dataset$cp , dataset$target)
print(ccp)
cfbs=chisq.test(dataset$fbs , dataset$target)
print(cfbs)
crestecg=chisq.test(dataset$restecg , dataset$target)
print(crestecg)
cexang=chisq.test(dataset$exang , dataset$target)
print(cexang)
cslope=chisq.test(dataset$slope , dataset$target)
print(cslope)
cca=chisq.test(dataset$ca , dataset$target)
print(cca)
cthal=chisq.test(dataset$thal , dataset$target)
print(cthal)
cage= chisq.test(dataset$age, dataset$target)
print(cage)
ctrestbps=chisq.test(dataset$trestbps ,dataset$target)
print(ctrestbps)
cchol=cor(dataset$chol ,dataset$target)
print(cchol)
cthalach=cor(dataset$thalach ,dataset$target)
print(cthalach)
coldpeak=cor(dataset$oldpeak ,dataset$target)
print(coldpeak)
dataset <- dataset[, -which(names(dataset) == "fbs")]
head(dataset)
ncol(dataset)
nrow(dataset)
dataset$target <- as.factor(dataset$target)
install.packages("partykit")
install.packages("ggplot2")
library(party)
library(partykit)
library(RWeka)
install.packages("ggplot2")
library(factoextra)
fviz_nbclust(dataset, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
library(factoextra)
fviz_nbclust(USArrests, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# 2- silhouette method
#install.packages("NbClust")
library(NbClust)
#a)fviz_nbclust() with silhouette method using library(factoextra)
fviz_nbclust(USArrests, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
# 1 - view
data("USArrests")
summary(USArrests)
str(USArrests)
# 2- prepreocessing
#Data types should be transformed into numeric types before clustering.
USArrests <- scale(USArrests)
View(USArrests)
# 3- run k-means clustering to find 4 clusters
#set a seed for random number generation  to make the results reproducible
set.seed(8953)
kmeans.result <- kmeans(USArrests, 4)
# print the clusterng result
kmeans.result
#4- visualize clustering
#install.packages("factoextra")
library(factoextra)
fviz_cluster(kmeans.result, data = USArrests)
# plot cluster points
plot(USArrests[, c("Murder","Assault")], col = (kmeans.result$cluster) )
# this command add Points(center) to a Plot
points(kmeans.result$centers[, c("Murder","Assault")],  col = 1:4, pch = 8, cex=2)
# plot cluster points
plot(USArrests[, c("UrbanPop","Rape")], col = (kmeans.result$cluster) )
# this command add Points(center) to a Plot
points(kmeans.result$centers[, c("UrbanPop","Rape")],  col = 1:4, pch = 8, cex=10)
#------------------------------------------------k-means clustering 2---------------------------------------------------
#install.packages("fpc")
library(fpc)
#kmeansruns() : It calls  kmeans() to perform  k-means clustering
#It initializes the k-means algorithm several times with random points from the data set as means.
#It estimates the number of clusters by Calinski Harabasz index or average silhouette width
kmeansruns.result <- kmeansruns(USArrests)
kmeansruns.result
fviz_cluster(kmeansruns.result, data = USArrests)
#--------------------------------------------------k-mediods clustering with PAM--------------------------------------------------
#install.packages("cluster")
library(cluster)
# group into 4 clusters
pam.result <- pam(USArrests, 4)
plot(pam.result)
##----Hierarchical Clustering of the USArrest Data-----##
set.seed(2835)
# draw a sample of 40 records from the USArrests data, so that the clustering plot will not be over crowded
idx <- sample(1:dim(USArrests)[1], 40)
USArrests2 <- USArrests[idx, ]
## hiercrchical clustering
library(factoextra)
hc.cut <- hcut(USArrests2, k = 2, hc_method = "complete") # Computes Hierarchical Clustering and Cut the Tree
# Visualize dendrogram
fviz_dend(hc.cut,rect = TRUE)  #logical value specifying whether to add a rectangle around groups.
# Visualize cluster
fviz_cluster(hc.cut, ellipse.type = "convex") # Character specifying frame type. Possible values are 'convex', 'confidence' etc
#---------------------------------------------Validation ---------------------------------------------
#average silhouette for each clusters
library(cluster)
avg_sil <- silhouette(kmeans.result$cluster,dist(USArrests)) #a dissimilarity object inheriting from class dist or coercible to one. If not specified, dmatrix must be.
fviz_silhouette(avg_sil)#k-means clustering with estimating k and initializations
# 1-  define function to compute average silhouette for k clusters using silhouette()
silhouette_score <- function(k){
km <- kmeans(USArrests, centers = k,nstart=25) # if centers is a number, how many random sets should be chosen?
ss <- silhouette(km$cluster, dist(USArrests))
sil<- mean(ss[, 3])
return(sil)
}
##  k cluster range from 2 to 10
k <- 2:10
##  call  function fore k value
avg_sil <- sapply(k, silhouette_score)  ##Apply a Function over a List or Vector
plot(k, type='b', avg_sil, xlab='Number of clusters', ylab='Average Silhouette Scores', frame=FALSE)
# 2- silhouette method
#install.packages("NbClust")
library(NbClust)
#a)fviz_nbclust() with silhouette method using library(factoextra)
fviz_nbclust(USArrests, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
#b) NbClust validation
fres.nbclust <- NbClust(USArrests, distance="euclidean", min.nc = 2, max.nc = 10, method="kmeans", index="all")
# 3- Elbow method
#fviz_nbclust() with within cluster sums of squares (wss) method
library(factoextra)
fviz_nbclust(USArrests, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 2)+
labs(subtitle = "Elbow method")
# 2- silhouette method
#install.packages("NbClust")
library(NbClust)
#a)fviz_nbclust() with silhouette method using library(factoextra)
fviz_nbclust(USArrests, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
#b) NbClust validation
fres.nbclust <- NbClust(USArrests, distance="euclidean", min.nc = 2, max.nc = 10, method="kmeans", index="all")
#install.packages("NbClust")
library(NbClust)
#a)fviz_nbclust() with silhouette method using library(factoextra)
fviz_nbclust(USArrests, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method")
fres.nbclust<-NbClust(dataset, distance="euclidean", min.nc= 2, max.nc= 10, method="kmeans", index="all")
fres.nbclust<-NbClust(dataset, distance="euclidean", min.nc= 2, max.nc= 10, method="kmeans", index="all")
