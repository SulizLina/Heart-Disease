same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
}
# Calculate average precision and recall
precision <- precision_sum / n
recall <- recall_sum / n
return(list(precision = precision, recall = recall))
}
# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)
# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall
# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
km <- kmeans(dataset, 3, iter.max = 140 , algorithm="Lloyd", nstart=100)
km
fviz_cluster(list(data = dataset, cluster = km$cluster),
ellipse.type = "norm", geom = "point", stand = FALSE,
palette = "jco", ggtheme = theme_classic())
sil <- silhouette(km$cluster, dist(dataset))
rownames(sil) <- rownames(dataset)
fviz_silhouette(sil)
km$tot.withinss
cluster_assignments <- c(km$cluster)
ground_truth_labels <- c(dataBeforC$target)
data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)
# Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
n <- nrow(data)
precision_sum <- 0
recall_sum <- 0
for (i in 1:n) {
cluster <- data$cluster[i]
label <- data$label[i]
# Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
}
# Calculate average precision and recall
precision <- precision_sum / n
recall <- recall_sum / n
return(list(precision = precision, recall = recall))
}
# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)
# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall
# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
km <- kmeans(dataset, 4, iter.max = 140 , algorithm="Lloyd", nstart=100)
km
fviz_cluster(list(data = dataset, cluster = km$cluster),
ellipse.type = "norm", geom = "point", stand = FALSE,
palette = "jco", ggtheme = theme_classic())
sil <- silhouette(km$cluster, dist(dataset))
rownames(sil) <- rownames(dataset)
fviz_silhouette(sil)
km$tot.withinss
cluster_assignments <- c(km$cluster)
ground_truth_labels <- c(dataBeforC$target)
data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)
#Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
n <- nrow(data)
precision_sum <- 0
recall_sum <- 0
for (i in 1:n) {
cluster <- data$cluster[i]
label <- data$label[i]
#Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
#Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
#Count the total number of items with the same category
total_same_category <- sum(data$label == label)
#Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
}
#Calculate average precision and recall
precision <- precision_sum / n
recall <- recall_sum / n
return(list(precision = precision, recall = recall))
}
#Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)
# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall
#Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
C45Fit <- J48(target~.,data=train_data)
table(predict(C45Fit), train_data$target,positive="1")
testPred<- predict(fit.tree,newdata=test_data,type="class")
results<- confusionMatrix(testPred,test_data$target,positive="1")
print(results)
testPred<- predict(dataset_ctree,newdata=test_data)
results<- confusionMatrix(testPred,test_data$target,positive="1")
print(results)
C45Fit <- J48(target~.,data=train_data)
table(predict(C45Fit), train_data$target)
print(C45Fit)
plot(C45Fit)
plot(C45Fit,type="simple")
install.packages("ggplot2")
library(mlbench)
library(aod)
library(mlbench)
library(dplyr)
library(ggplot2)
library(pROC)
library(stats)
library(rpart.plot)
library(randomForest)
library(gbm)
library(class)
library(patchwork)
library(e1071)
library(caret)
data= read.csv('DataSet/heart.csv')
head(data)
sum(duplicated(data))
data[c(61,65,119,669),]
dataset <- data[!duplicated(data), ]
dataset
sum(duplicated(dataset))
ncol(dataset)
nrow(dataset)
summary(dataset$age)
var(dataset$age)
summary(dataset$trestbps)
var(dataset$trestbps)
summary (dataset$chol)
var(dataset$chol)
summary(dataset$thalach)
var(dataset$thalach)
summary(dataset$oldpeak)
var(dataset$oldpeak)
boxplot(dataset$age)
boxplot(dataset$trestbps)
boxplot(dataset$chol)
boxplot(dataset$thalach)
boxplot(dataset$oldpeak)
tab <- dataset$target %>% table()
percentages <- tab %>% prop.table() %>% round(3) * 100
txt <- paste0(names(tab), '\n', percentages, '%')
pie(tab, labels = txt, main="percentage of the target")
ggplot(dataset, aes(x = sex, fill = as.factor(target))) +
geom_bar(stat = "count", position = "stack", width = 0.6, show.legend = TRUE) +
geom_text(aes(label = after_stat(count)), stat = 'count', position = position_stack(vjust = 0.5)) +
labs(x = "Sex", y = "Count",fill="target")
ggplot(dataset, aes(x = cp, fill = as.factor(target))) +
geom_bar(stat = "count", position = "stack", width = 0.6, show.legend = TRUE) +
geom_text(aes(label = after_stat(count)), stat = 'count', position = position_stack(vjust = 0.5)) +
labs(x = "cp", y = "Count",fill="target")
ggplot(dataset, aes(x = ca, fill = as.factor(target))) +
geom_bar(stat = "count", position = "stack", width = 0.6, show.legend = TRUE) +
geom_text(aes(label = after_stat(count)), stat = 'count', position = position_stack(vjust = 0.5)) +
labs(x = "ca", y = "Count",fill="target")
plot(dataset$target,dataset$thalach)
plot(dataset$age, dataset$trestbps, pch = 16, col = "black", xlab = "Age", ylab = "trestbps", main = "Scatter Plot for Age and trestbps")
abline(lm(dataset$trestbps ~ dataset$age), col = "red", lwd = 2)
plot(dataset$thalach, dataset$oldpeak, pch = 16, col = "black", xlab = "thalach", ylab = "oldpeak", main = "Scatter Plot for thalach and oldpeak")
abline(lm(dataset$oldpeak ~ dataset$thalach), col = "red", lwd = 2)
plot(dataset$chol,dataset$target)
ggplot(dataset, aes(x = fbs, fill = as.factor(target))) +
geom_bar(stat = "count", position = "stack", width = 0.6, show.legend = TRUE) +
geom_text(aes(label = after_stat(count)), stat = 'count', position = position_stack(vjust = 0.5)) +
labs(x = "fbs", y = "Count",fill="target")
sum(is.na(data))
boxplot.stats(dataset$age)$out
boxplot.stats(dataset$trestbps)$out
boxplot.stats(dataset$chol)$out
boxplot.stats(dataset$thalach)$out
boxplot.stats(dataset$oldpeak)$out
dataset[129,5]=246.5
dataset[dataset$ca != "3" & dataset$ca != "1" & dataset$ca != "2" & dataset$ca != "0",]
dataset[dataset$sex != "0" & dataset$sex!= "1",]
dataset[dataset$fbs != "0" & dataset$fbs != "1",]
dataset[dataset$restecg != "0" & dataset$restecg != "1" & dataset$restecg != "2" ,]
dataset[dataset$exang != "0" & dataset$exang != "1",]
dataset[dataset$slope != "0" & dataset$slope != "1" & dataset$slope != "2" ,]
dataset[dataset$thal != "1" & dataset$thal != "2" & dataset$thal != "3" ,]
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]}
a=getmode(dataset$ca)
print(a)
dataset[dataset$ca=="4","ca"]<-a
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]}
b=getmode(dataset$thal)
print(b)
dataset[dataset$thal=="0","thal"]<-b
dataset$trestbps <- ifelse(dataset$trestbps <=90, "Low",
ifelse(dataset$trestbps <= 120, "Normal",
ifelse(dataset$trestbps <= 129, "Elevated",
ifelse(dataset$trestbps <= 139, "High Stage 1",
ifelse(dataset$trestbps <= 180, "High Stage 2",
ifelse(dataset$trestbps > 180, "High Stage 3",0))))))
trestbpsdis <- dataset$trestbps
print(trestbpsdis)
AgeBeforeDis <- dataset$age
dataset$age <- ifelse(dataset$age <= 16, "Children",
ifelse(dataset$age <= 39, "Young Adults",
ifelse(dataset$age <= 59, "Middle-aged Adults",
ifelse(dataset$age < 99, "Old Adults",0))))
agedis <- dataset$age
print(agedis)
min_max_normalize <- function(x) {
(x - min(x)) / (max(x) - min(x))}
dataset$chol <- min_max_normalize(dataset$chol)
print(dataset$chol)
dataset$oldpeak <- min_max_normalize(dataset$oldpeak)
print(dataset$oldpeak)
dataset$thalach <- min_max_normalize(dataset$thalach)
print(dataset$thalach)
sexencoding <- dataset$sex
print(sexencoding)
dataset$trestbps=factor(dataset$trestbps,levels=c("Low","Normal","Elevated","High Stage 1","High Stage 2","High Stage 3"),labels=c(0,1,2,3,4,5))
dataset$age=factor(dataset$age,levels=c("Children","Young Adults","Middle-aged Adults","Old Adults"),labels=c(0,1,2,3))
csex=chisq.test(dataset$sex , dataset$target)
print(csex)
ccp=chisq.test(dataset$cp , dataset$target)
print(ccp)
cfbs=chisq.test(dataset$fbs , dataset$target)
print(cfbs)
crestecg=chisq.test(dataset$restecg , dataset$target)
print(crestecg)
cexang=chisq.test(dataset$exang , dataset$target)
print(cexang)
cslope=chisq.test(dataset$slope , dataset$target)
print(cslope)
cca=chisq.test(dataset$ca , dataset$target)
print(cca)
cthal=chisq.test(dataset$thal , dataset$target)
print(cthal)
cage= chisq.test(dataset$age, dataset$target)
print(cage)
ctrestbps=chisq.test(dataset$trestbps ,dataset$target)
print(ctrestbps)
cchol=cor(dataset$chol ,dataset$target)
print(cchol)
cthalach=cor(dataset$thalach ,dataset$target)
print(cthalach)
coldpeak=cor(dataset$oldpeak ,dataset$target)
print(coldpeak)
dataset <- dataset[, -which(names(dataset) == "fbs")]
head(dataset)
ncol(dataset)
nrow(dataset)
dataset$target <- as.factor(dataset$target)
install.packages("partykit")
library(party)
library(partykit)
library(RWeka)
library(caret)
library(rpart)
library(rpart.plot)
set.seed(1234)
ind=sample(2, nrow(dataset), replace=TRUE, prob=c(0.70 , 0.30))
train_data=dataset[ind==1,]
test_data=dataset[ind==2,]
dim(train_data)
dim(test_data)
myFormula<- target~ age + sex + cp + trestbps + chol + restecg + thalach + exang + oldpeak + slope + ca + thal
dataset_ctree<-ctree(myFormula, data=train_data)
table(predict(dataset_ctree), train_data$target)
print(dataset_ctree)
plot(dataset_ctree)
plot(dataset_ctree,type="simple")
testPred<- predict(dataset_ctree,newdata=test_data)
results<- confusionMatrix(testPred,test_data$target,positive="1")
print(results)
C45Fit <- J48(target~.,data=train_data)
table(predict(C45Fit), train_data$target)
print(C45Fit)
plot(C45Fit)
plot(C45Fit,type="simple")
testPred<- predict(C45Fit,newdata=test_data)
results<- confusionMatrix(testPred,test_data$target,positive="1")
print(results)
fit.tree=rpart(target~., data=train_data, method="class",cp=0.008)
print(fit.tree)
rpart.plot(fit.tree)
testPred<- predict(fit.tree,newdata=test_data,type="class")
results<- confusionMatrix(testPred,test_data$target,positive="1")
print(results)
set.seed(1234)
ind=sample (2, nrow(dataset), replace=TRUE, prob=c(0.75 , 0.25))
train_data=dataset[ind==1,]
test_data=dataset[ind==2,]
dim(train_data)
dim(test_data)
myFormula<- target~ age + sex + cp + trestbps + chol + restecg + thalach + exang + oldpeak + slope + ca + thal
dataset_ctree<-ctree(myFormula, data=train_data)
table(predict(dataset_ctree), train_data$target)
print(dataset_ctree)
plot(dataset_ctree)
plot(dataset_ctree,type="simple")
testPred<- predict(dataset_ctree,newdata=test_data)
results<- confusionMatrix(testPred,test_data$target,positive="1")
print(results)
C45Fit <- J48(target~.,data=train_data)
table(predict(C45Fit), train_data$target)
C45Fit
plot(C45Fit)
plot(C45Fit,type="simple")
testPred<- predict(C45Fit,newdata=test_data)
results<- confusionMatrix(testPred,test_data$target,positive="1")
print(results)
fit.tree=rpart(target~., data=train_data, method="class",cp=0.008)
print(fit.tree)
rpart.plot(fit.tree)
testPred<- predict(fit.tree,newdata=test_data,type="class")
results<- confusionMatrix(testPred,test_data$target,positive="1")
print(results)
set.seed(1234)
ind=sample (2, nrow(dataset), replace=TRUE, prob=c(0.80 , 0.20))
train_data=dataset[ind==1,]
test_data=dataset[ind==2,]
dim(train_data)
dim(test_data)
myFormula<- target~ age + sex + cp + trestbps + chol + restecg + thalach + exang + oldpeak + slope + ca + thal
dataset_ctree<-ctree(myFormula, data=train_data)
table(predict(dataset_ctree), train_data$target)
print(dataset_ctree)
plot(dataset_ctree)
plot(dataset_ctree,type="simple")
testPred<- predict(dataset_ctree,newdata=test_data)
results<- confusionMatrix(testPred,test_data$target,positive="1")
print(results)
C45Fit <- J48(target~.,data=train_data)
table(predict(C45Fit), train_data$target)
print(C45Fit)
plot(C45Fit)
plot(C45Fit,type="simple")
testPred<- predict(C45Fit,newdata=test_data)
results<- confusionMatrix(testPred,test_data$target,positive="1")
print(results)
fit.tree=rpart(target~., data=train_data, method="class",cp=0.008)
print(fit.tree)
rpart.plot(fit.tree)
testPred<- predict(fit.tree,newdata=test_data,type="class")
results<- confusionMatrix(testPred,test_data$target,positive="1")
print(results)
dataBeforC<-dataset #in case we need the old data set(with the class label)
dataset <- dataset[, -which(names(dataset) == "target")]
dataset$age <- AgeBeforeDis
dataset$sex <- as.numeric(dataset$sex )
dataset$cp <- as.numeric(dataset$cp )
dataset$trestbps <- as.numeric(dataset$trestbps  )
dataset$restecg <- as.numeric(dataset$restecg )
dataset$thalach <- as.numeric(dataset$thalach)
dataset$exang <- as.numeric(dataset$exang)
dataset$slope <- as.numeric(dataset$slope)
dataset$ca <- as.numeric(dataset$ca)
dataset$thal <- as.numeric(dataset$thal)
dataset$age <- as.numeric(dataset$age)
str(dataset)
install.packages("factoextra")
library(factoextra)
library(NbClust)
library(cluster)
fviz_nbclust(dataset, kmeans, method = "silhouette")+labs(subtitle ="Silhouette method")
km <- kmeans(dataset, 2, iter.max = 140 , algorithm="Lloyd", nstart=100)
km
fviz_cluster(list(data = dataset, cluster = km$cluster),
ellipse.type = "norm", geom = "point", stand = FALSE,
palette = "jco", ggtheme = theme_classic())
sil <- silhouette(km$cluster, dist(dataset))
rownames(sil) <- rownames(dataset)
fviz_silhouette(sil)
km$tot.withinss
cluster_assignments <- c(km$cluster)
ground_truth_labels <- c(dataBeforC$target)
data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)
# Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
n <- nrow(data)
precision_sum <- 0
recall_sum <- 0
for (i in 1:n) {
cluster <- data$cluster[i]
label <- data$label[i]
# Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
}
# Calculate average precision and recall
precision <- precision_sum / n
recall <- recall_sum / n
return(list(precision = precision, recall = recall))
}
# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)
# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall
# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
km <- kmeans(dataset, 3, iter.max = 140 , algorithm="Lloyd", nstart=100)
km
fviz_cluster(list(data = dataset, cluster = km$cluster),
ellipse.type = "norm", geom = "point", stand = FALSE,
palette = "jco", ggtheme = theme_classic())
sil <- silhouette(km$cluster, dist(dataset))
rownames(sil) <- rownames(dataset)
fviz_silhouette(sil)
km$tot.withinss
cluster_assignments <- c(km$cluster)
ground_truth_labels <- c(dataBeforC$target)
data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)
# Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
n <- nrow(data)
precision_sum <- 0
recall_sum <- 0
for (i in 1:n) {
cluster <- data$cluster[i]
label <- data$label[i]
# Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
}
# Calculate average precision and recall
precision <- precision_sum / n
recall <- recall_sum / n
return(list(precision = precision, recall = recall))
}
# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)
# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall
# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
km <- kmeans(dataset, 4, iter.max = 140 , algorithm="Lloyd", nstart=100)
km
fviz_cluster(list(data = dataset, cluster = km$cluster),
ellipse.type = "norm", geom = "point", stand = FALSE,
palette = "jco", ggtheme = theme_classic())
sil <- silhouette(km$cluster, dist(dataset))
rownames(sil) <- rownames(dataset)
fviz_silhouette(sil)
km$tot.withinss
cluster_assignments <- c(km$cluster)
ground_truth_labels <- c(dataBeforC$target)
data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)
#Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
n <- nrow(data)
precision_sum <- 0
recall_sum <- 0
for (i in 1:n) {
cluster <- data$cluster[i]
label <- data$label[i]
#Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
#Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
#Count the total number of items with the same category
total_same_category <- sum(data$label == label)
#Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
}
#Calculate average precision and recall
precision <- precision_sum / n
recall <- recall_sum / n
return(list(precision = precision, recall = recall))
}
#Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)
# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall
#Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
